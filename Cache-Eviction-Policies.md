## **What is cache eviction?**

> **Eviction** = Removing items from cache when cache is full (to make space for new data)

ğŸ—‚ï¸ **Cache = Limited memory**
â†’ You canâ€™t store everything forever â†’ Must evict less useful data

---

## **Common Cache Eviction Policies** (with small real-world analogy)

| **Policy**                      | **Meaning**                                   | **Real-life analogy**                                     |
| ------------------------------- | --------------------------------------------- | --------------------------------------------------------- |
| **LRU (Least Recently Used)**   | Remove the item not accessed for longest time | Bookshelf â€” remove the book you havenâ€™t touched in months |
| **LFU (Least Frequently Used)** | Remove item with **least # of accesses**      | TV shows â€” delete show you watched only once              |
| **FIFO (First In First Out)**   | Remove **oldest added** item                  | First water bottle you put in fridge gets removed first   |
| **MRU (Most Recently Used)**    | Remove most recently accessed item (rare)     | Remove the book you just read (not common)                |
| **Random**                      | Evict random item                             | Pick any bottle and throw out (used in simple systems)    |
| **TTL (Time To Live)**          | Remove item after fixed time expiry           | Milk carton expires after 3 days                          |

---

## **Quick Summary Table (Pros & Cons)**

| **Policy** | **Good whenâ€¦**                                         | **Pros**               | **Cons**                       |
| ---------- | ------------------------------------------------------ | ---------------------- | ------------------------------ |
| **LRU**    | Recent items likely reused (web pages)                 | Intuitive, widely used | Slightly more metadata needed  |
| **LFU**    | Items with **high re-use freq** matter (config values) | Captures frequency     | Slow to adapt to recent trends |
| **FIFO**   | Very simple cases                                      | Easy to implement      | Doesnâ€™t consider usage         |
| **MRU**    | Access pattern flips fast (rare)                       | Niche cases            | Rarely useful                  |
| **Random** | Small/simple cache                                     | Ultra fast             | Unpredictable                  |
| **TTL**    | Data expires naturally (weather, prices)               | Auto refresh           | Can expire useful data         |

---

## **Where these are used (Real systems)**

| **System**           | **Policy used**               |
| -------------------- | ----------------------------- |
| **Redis**            | LRU, LFU, TTL (all supported) |
| **CDN (Cloudflare)** | TTL + LRU                     |
| **Browser cache**    | LRU                           |
| **Memcached**        | LRU                           |

---

## **In short (interview answer)**

> **Cache eviction = free up space by removing items**
> Common policies:
> **LRU** (most used), **LFU**, **FIFO**, **TTL** â€”
> Choose based on access pattern & app needs.

---

## **Tiny real example (Redis)**

```bash
# Set maxmemory & eviction policy (Redis)
CONFIG SET maxmemory 100mb
CONFIG SET maxmemory-policy allkeys-lru
```

â†’ Redis will evict **least recently used keys** when 100 MB full

---

## **Pro tip for interview**

If youâ€™re unsure, **default safe answer = LRU**
(It balances recency and practical use)

---

Perfect â€” letâ€™s make a **clean table** of:
ğŸ”¹ **Policy â†’ Use case â†’ Why**
So in real system design interviews, you know **exactly where to apply each** ğŸ‘‡

---

## **Cache eviction policies â€” where to apply in real systems**

| **Policy**                            | **Best used in...**                                                                | **Why it works well**                                                      |
| ------------------------------------- | ---------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
| **LRU (Least Recently Used)**         | **Web page caching (CDN, browser)**<br>**API response cache (Redis, Memcached)**   | Users often revisit **recent pages**<br>â†’ Old pages become less useful     |
| **LFU (Least Frequently Used)**       | **Config values cache**<br>**Dictionary lookup (common terms)**                    | Some data is **repeatedly used a lot**<br>â†’ Keep items with high reuse     |
| **FIFO (First In First Out)**         | **Streaming apps (Video chunk buffer)**<br>**Batch processing queues**             | You naturally want **oldest data out first**<br>â†’ Process in arrival order |
| **MRU (Most Recently Used)** *(rare)* | **Undo history (Text editor)**<br>**Session cleanup (if user comes back soon)**    | When **recent data is least useful**<br>â†’ Unusual, niche cases             |
| **Random**                            | **Very small caches (IoT devices)**<br>**Simple embedded systems**                 | Hardware/resource constrained<br>â†’ Simpler, faster eviction logic          |
| **TTL (Time To Live)**                | **Weather data API**<br>**Stock prices cache**<br>**Product catalog (E-commerce)** | Data **naturally expires/changes**<br>â†’ Expiry ensures freshness           |

---

## **Interview-ready crisp examples** (You can say like this)

> âœ¨ *â€œFor a web app with heavy reads (e.g. e-commerce product pages), Iâ€™d use **LRU cache** in Redis to serve hot products fast â€” as users mostly revisit recent products.â€*

> âœ¨ *â€œFor config flags or common lookup tables, **LFU** makes sense to keep frequently accessed keys longer.â€*

> âœ¨ *â€œIf caching weather or stock data, Iâ€™d apply **TTL** of 10 mins so users get fresh info automatically.â€*

---

## **If you want an easy rule of thumb ğŸ¥³**

| **Pattern**             | **Policy** |
| ----------------------- | ---------- |
| Recent data reused?     | **LRU**    |
| Frequently reused data? | **LFU**    |
| Data expires naturally? | **TTL**    |
| Stream / Queue?         | **FIFO**   |
| Tiny embedded system?   | **Random** |

---

**Quick tip (interview)**
If unsure â†’ **LRU is almost always a safe answer for general purpose caches**


## **"Under the hood, how does a cache implement LRU/LFU etc.?"**

---

## ğŸš€ **First â€” High level**

> **Eviction policy** (LRU, LFU etc.) = **Strategy**
>
> **Algorithm + Data structures** = **How to efficiently implement it**

---

## **LRU (Least Recently Used)** â€” Common algorithm

### ğŸ¯ **Goal**: Quickly find and evict least recently accessed item

### âš™ï¸ **Typical algorithm**:

â¡ï¸ Use **HashMap + Doubly Linked List**

| Data structure           | Purpose                 |
| ------------------------ | ----------------------- |
| **HashMap** (key â†’ node) | Fast O(1) lookup        |
| **Doubly linked list**   | Maintains recency order |

ğŸ› ï¸ **How it works**

* On **get() / put()** â†’ move item to **head (most recent)**
* Evict from **tail (least recent)**

### **Time complexity**

âœ… get() â†’ O(1)
âœ… put() â†’ O(1)

### ğŸ“Œ **Example** (Java-ish)

```java
class LRUCache {
  Map<Key, Node> map;
  DoublyLinkedList list;
}
```

---

## **LFU (Least Frequently Used)** â€” Common algorithm

### ğŸ¯ **Goal**: Evict least frequently accessed item

### âš™ï¸ **Typical algorithm**:

â¡ï¸ Use **HashMap + Frequency List**

| Data structure                           | Purpose            |
| ---------------------------------------- | ------------------ |
| **HashMap (key â†’ node)**                 | O(1) lookup        |
| **FreqMap (freq â†’ linked list of keys)** | Group keys by freq |
| Track **minFreq**                        | Find LFU key fast  |

ğŸ› ï¸ **How it works**

* On get/put â†’ increment freq
* Move node to **next freq list**
* Evict node from **minFreq list** when full

### **Time complexity**

âœ… get() â†’ O(1)
âœ… put() â†’ O(1)

---

## ğŸŸ¥ **Redis â€” What algorithm does Redis use?**

Redis supports **multiple eviction policies** â€” hereâ€™s how **Redis implements them**:

| **Redis Policy**                   | **Redis Algorithm**                                 |
| ---------------------------------- | --------------------------------------------------- |
| **allkeys-lru** / **volatile-lru** | **Approximate LRU** using **LRU clock + sampling**  |
| **allkeys-lfu**                    | **Approximate LFU** with **8-bit counters + decay** |
| **volatile-ttl**                   | Evict keys expiring soonest (based on TTL)          |
| **noeviction**                     | Just error on memory full                           |

---

## ğŸ” **Why Redis uses Approximate LRU/LFU (not exact)?**

* **Exact LRU/LFU (O(1))** â†’ more metadata + complex
* Redis uses **simple counters + random sampling** (fast & good enough)

### ğŸ“Œ **Approx LRU example**

* Each key stores a **last access timestamp (LRU clock)**
* Redis samples **5 random keys**
* Evicts key with **oldest timestamp** among sampled ones

â†’ **Fast & scalable**, especially for millions of keys

---

## **Redis LFU â€” How does it work?**

* Each key has **8-bit counter** (max 255)
* On access â†’ increment counter (with probability)
* Counter **decays** over time (so stale keys drop freq)

---

## **In short (interview ready)**

> **Cache design = eviction policy + fast data structure**

* **LRU** â†’ HashMap + Doubly Linked List
* **LFU** â†’ HashMap + Freq Lists + minFreq
* **Redis** uses **Approximate LRU/LFU** via **sampling + counters** (for speed)

---

## **Pro tip (interview)**

> âœ¨ *â€œRedis trades perfect LRU/LFU accuracy for speed and simplicity â€” using sampling and approximate counters.â€*
